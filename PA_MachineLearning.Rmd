---
title: "ProjectAssignmentML"
author: "G. Hol"
date: "December 4, 2017"
output: html_document
---

##Summary

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. The goal is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants and predict the manner in which they did the exercise. The random forest model had an accuracy of 0.993.

Data
The training data: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
The test data: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv
Data source: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har. 

Approach: 
0. install libraries; load data; set seed
1. explore data to decide on preprocessing steps
2. select only explaning variables that occurred in the test data set; exclude time measurements.
3. create own testing data set to enable cross validation
4. run random forest and cross validate 
5. apply the 'best' model to predict classe for the testing data set

```{r basics}
#step 0

library(caret); library(klaR); library(randomForest)
set.seed(32343)

fileurl1<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
training<-read.csv(fileurl1,stringsAsFactors = FALSE)
fileurl2<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testing<-read.csv(fileurl2,stringsAsFactors = FALSE)
training$classe<-as.factor(training$classe)
```

During data exploration I noticed a high numbers of NAs, and decided to only use variables that occurred in the test dataset. I also looked at the correlation between predictors; those were high and thus I decided to use pca for preprocessing.
Here a data partition is made to create an own testing set to test how well the model is at prediction the correct classes.
```{r exploration, echo=FALSE}
#step 2 only train with columns that are not NA in the testing data set 
subtraining<-training[,colSums(is.na(testing))==0]

# step 3 create own testing set to cross validate the model; exclude time measurements
inTrain<-createDataPartition(y=subtraining$classe, p=0.75, list=F)
training2<-subtraining[inTrain,c(2,8:60)]
testing2<-subtraining[-inTrain,c(2,8:60)]

#step 1
M<-abs(cor(training2[,-c(1,54)]))
#some of the predictors are highly correlated -> pca preprocessing?

```

```{r modelling}
#step 4
modrf<-train(classe ~., method="rf", data=training2) 

prf<-predict(modrf,testing2)

#out of sample error
sum(prf==testing2$classe)/nrow(testing2)

#step 5 Course Project Prediction Quiz Portion
predict(modrf, testing)
```

Random forest gave the highest accuracy, with more than 99% cases correctly predicted.
